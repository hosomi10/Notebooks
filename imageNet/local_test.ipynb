{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログ用画像保存先指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "blocked_dir = 'local_test/blocked'\n",
    "free_dir = 'local_test/free'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(free_dir)\n",
    "    os.makedirs(blocked_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')\n",
    "    \n",
    "try:\n",
    "    with open('local_test/' + datetime.datetime.now().strftime('%Y%m%d')+'_log.txt','x') as f:\n",
    "        f.write('image_name' +  '\t' + 'classification' + '\t' +'prob_blocked')\n",
    "except FileExistsError:\n",
    "    print('Logfile already exist')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load the trained model(学習済みモデルの読み込み)\n",
    "\n",
    "We'll assumed that you've already downloaded the best_model.pth to your workstation as instructed in the training notebook. Now, you should upload this model into this notebook's directory by using the Jupyter Lab upload tool. Once that's finished there should be a file named best_model.pth in this notebook's directory. \n",
    "\n",
    "(追加) ローカルの学習なので、すでにbest_model.pthがローカルに存在している事を前提とします。\n",
    "\n",
    "\n",
    "Please make sure the file has uploaded fully before calling the next cell\n",
    "\n",
    "Execute the code below to initialize the PyTorch model. This should look very familiar from the training notebook.\n",
    "\n",
    "(訳) Pytorch modelの初期化を下記コードでおこないます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、best_model.pthから、学習した重みを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../model/best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在、モデルの重みは、CPUメモリーで実行されているので、下記コードでGPUに転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda')\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the preprocessing function(事前処理関数の作成)\n",
    "\n",
    "We have now loaded our model, but there's a slight issue. The format that we trained our model doesnt exactly match the format of the camera. To do that, we need to do some preprocessing. This involves the following steps\n",
    "\n",
    "(訳) モデルを読み込みましたが、まだわずかな問題があります。学習済みモデルのフォーマットと、カメラの形式と完全に一致しません。これを解消するために、 いくつかの前処理を行う必要があります。これらは、下記の手順になります。\n",
    "1.Convert from BGR to RGB\n",
    "2.Convert from HWC layout to CHW layout\n",
    "3.Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "4.Transfer the data from CPU memory to GPU memory\n",
    "5.Add a batch dimension\n",
    "\n",
    "(訳)\n",
    "1.BGRからRGBに変換\n",
    "2.HWC layoutからCHW layoutに変換\n",
    "3.トレーニング中に使ったのと同じパラメーターを使用して正規化します（カメラは[0、255]の範囲の値を提供し、ロードされた画像は[0、1]の範囲でトレーニングするため、255.0でスケーリングする必要があります\n",
    "4.dataをCPUメモリからGPUメモリに転送します\n",
    "5.バッチディメンションを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像保存メソッドの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def save_image(directory,im_name):\n",
    "    cap_image=image\n",
    "    image_path = os.path.join(directory, im_name)\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(cap_image.value)\n",
    "\n",
    "def save_log(classification):\n",
    "    global im_name,blocked_slider\n",
    "    write_log=open(os.path.join('log', datetime.datetime.now().strftime('%Y%m%d')+'_log.txt'),'a')\n",
    "    write_log.write('\\n'+im_name +  '\t' + classification+  '\t' + str(blocked_slider.value))\n",
    "    write_log.close()\n",
    "    \n",
    "def capture_snapshot(blocked_val):\n",
    "    global free_dir,blocked_dir,blocked_slider\n",
    "    if blocked_val < 0.5:\n",
    "        save_snapshot(free_dir)\n",
    "        save_log('free')\n",
    "    else:\n",
    "        save_snapshot(blocked_dir)\n",
    "        save_log('blocked')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ボタン動作定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def determine_image(test_image):\n",
    "    global blocked_slider\n",
    "    x = test_image \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    return prob_blocked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォルダセレクト,テスト実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/free/8f7fca6e-a16b-11ea-ae2f-72b5f773b75d.jpg\n",
      "0.6890029907226562\n",
      "../dataset/free/1cb7854e-a16b-11ea-ae2f-72b5f773b75d.jpg\n",
      "0.9693331122398376\n",
      "1.1111111111111112\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "count_error=0\n",
    "files =glob.glob(\"../dataset/free/*\")\n",
    "\n",
    "for fname in files: \n",
    "    test_img=cv2.imread(fname)\n",
    "    val_prob_blocked=determine_image(test_img)\n",
    "    if val_prob_blocked>0.5:\n",
    "        print(fname)\n",
    "        print(val_prob_blocked)\n",
    "        count_error=count_error+1\n",
    "\n",
    "print(count_error/len(files)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
