{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログ用画像保存先指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories not created becasue they already exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "blocked_dir = 'log/blocked'\n",
    "free_dir = 'log/free'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(free_dir)\n",
    "    os.makedirs(blocked_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')\n",
    "    \n",
    "try:\n",
    "    with open('log/' + datetime.datetime.now().strftime('%Y%m%d')+'_log.txt','x') as f:\n",
    "        f.write('image_name' +  '\t' + 'classification' + '\t' +'prob_blocked')\n",
    "except FileExistsError:\n",
    "    print('Logfile already exist')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load the trained model(学習済みモデルの読み込み)\n",
    "\n",
    "We'll assumed that you've already downloaded the best_model.pth to your workstation as instructed in the training notebook. Now, you should upload this model into this notebook's directory by using the Jupyter Lab upload tool. Once that's finished there should be a file named best_model.pth in this notebook's directory. \n",
    "\n",
    "(追加) ローカルの学習なので、すでにbest_model.pthがローカルに存在している事を前提とします。\n",
    "\n",
    "\n",
    "Please make sure the file has uploaded fully before calling the next cell\n",
    "\n",
    "Execute the code below to initialize the PyTorch model. This should look very familiar from the training notebook.\n",
    "\n",
    "(訳) Pytorch modelの初期化を下記コードでおこないます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、best_model.pthから、学習した重みを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在、モデルの重みは、CPUメモリーで実行されているので、下記コードでGPUに転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda')\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the preprocessing function(事前処理関数の作成)\n",
    "\n",
    "We have now loaded our model, but there's a slight issue. The format that we trained our model doesnt exactly match the format of the camera. To do that, we need to do some preprocessing. This involves the following steps\n",
    "\n",
    "(訳) モデルを読み込みましたが、まだわずかな問題があります。学習済みモデルのフォーマットと、カメラの形式と完全に一致しません。これを解消するために、 いくつかの前処理を行う必要があります。これらは、下記の手順になります。\n",
    "1.Convert from BGR to RGB\n",
    "2.Convert from HWC layout to CHW layout\n",
    "3.Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "4.Transfer the data from CPU memory to GPU memory\n",
    "5.Add a batch dimension\n",
    "\n",
    "(訳)\n",
    "1.BGRからRGBに変換\n",
    "2.HWC layoutからCHW layoutに変換\n",
    "3.トレーニング中に使ったのと同じパラメーターを使用して正規化します（カメラは[0、255]の範囲の値を提供し、ロードされた画像は[0、1]の範囲でトレーニングするため、255.0でスケーリングする必要があります\n",
    "4.dataをCPUメモリからGPUメモリに転送します\n",
    "5.バッチディメンションを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カメラ起動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "操作ボタン定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "button_layout = widgets.Layout(width='96px', height='48px')\n",
    "\n",
    "capture_button = widgets.Button(description='Capture', button_style='info', layout=button_layout)\n",
    "forward_button = widgets.Button(description='Forward', button_style='success', layout=button_layout)\n",
    "stop_button = widgets.Button(description='Stop', button_style='danger', layout=button_layout)\n",
    "left_button = widgets.Button(description='Left', button_style='success', layout=button_layout)\n",
    "right_button = widgets.Button(description='Right', button_style='success', layout=button_layout)\n",
    "back_button = widgets.Button(description='Back', button_style='success', layout=button_layout)\n",
    "\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0,step=0.01, orientation='vertical')\n",
    "speed_slider=widgets.FloatSlider(description='speed',value=0.3,min=0,max=1,step=0.01)\n",
    "turn_slider=widgets.FloatSlider(description='turn',value=0.3,min=0,max=1,step=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像保存メソッドの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "im_name='hoge'\n",
    "\n",
    "def save_snapshot(directory):\n",
    "    global im_name\n",
    "    cap_image=image\n",
    "    im_name=datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f') + '.jpg'\n",
    "    image_path = os.path.join(directory, im_name)\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(cap_image.value)\n",
    "\n",
    "def save_log(classification):\n",
    "    global im_name,blocked_slider\n",
    "    write_log=open(os.path.join('log', datetime.datetime.now().strftime('%Y%m%d')+'_log.txt'),'a')\n",
    "    write_log.write('\\n'+im_name +  '\t' + classification+  '\t' + str(blocked_slider.value))\n",
    "    write_log.close()\n",
    "    \n",
    "def capture_snapshot():\n",
    "    global free_dir,blocked_dir,blocked_slider\n",
    "    if blocked_slider.value < 0.5:\n",
    "        save_snapshot(free_dir)\n",
    "        save_log('free')\n",
    "    else:\n",
    "        save_snapshot(blocked_dir)\n",
    "        save_log('blocked')\n",
    "        \n",
    "#Captureボタンに動作追加\n",
    "capture_button.on_click(lambda x: capture_snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robotインスタンス生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ボタン動作定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def set_forward(change):\n",
    "    global robot,speed_slider\n",
    "    robot.stop()\n",
    "    robot.forward(speed_slider.value)\n",
    "\n",
    "def set_back(change):\n",
    "    global robot,speed_slider\n",
    "    robot.stop()\n",
    "    robot.backward(speed_slider.value)\n",
    "    \n",
    "def set_left(change):\n",
    "    global robot,turn_slider\n",
    "    robot.stop()\n",
    "    robot.left(turn_slider.value)\n",
    "    time.sleep(0.005)\n",
    "    robot.stop()\n",
    "\n",
    "def set_right(change):\n",
    "    global robot,turn_slider\n",
    "    robot.stop()\n",
    "    robot.right(turn_slider.value)\n",
    "    time.sleep(0.005)\n",
    "    robot.stop()\n",
    "\n",
    "def set_stop(change):\n",
    "    global robot\n",
    "    robot.stop()\n",
    "    \n",
    "def update(change):\n",
    "    global blocked_slider\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "\n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    blocked_slider.value = prob_blocked\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "update({'new': camera.value})  # we call the function once to intialize\n",
    "\n",
    "forward_button.on_click(set_forward)\n",
    "back_button.on_click(set_back)\n",
    "left_button.on_click(set_left)\n",
    "right_button.on_click(set_right)\n",
    "stop_button.on_click(set_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "操作パネル表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0a1f6fec8149feba6464f6654863cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='224', width='224'), FloatSlider(value=0.21, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a59fd8d2b54bfcb09fd414e09f5284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='info', description='Capture', layout=Layout(height='48px', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81cdfc3e02f4d5fa6146bdd6f253af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.3, description='speed', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d8d251e30e4c0593a884a0368e7b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.3, description='turn', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.HBox([image,blocked_slider]))\n",
    "control_box_1=widgets.HBox([capture_button,forward_button])\n",
    "v_control_box=widgets.VBox([stop_button,back_button])\n",
    "control_box_2=widgets.HBox([left_button,v_control_box,right_button])\n",
    "display(widgets.VBox([control_box_1,control_box_2]))\n",
    "display(speed_slider)\n",
    "display(turn_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デモ開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デモ終了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.left_motor.value = 0.0\n",
    "robot.right_motor.value = 0.0\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
